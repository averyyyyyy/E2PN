{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a486c720-eb7a-4847-b9e2-ac5e023b0ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"),'vgtk') )\n",
    "\n",
    "from SPConvNets.trainer_3dmatch import Trainer\n",
    "# from SPConvNets.options import opt as opt_3dmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f902e9f0-9a1d-4ded-a874-21c721282546",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad30369c-8509-41f9-9a16-e326bac1bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vgtk\n",
    "\n",
    "\n",
    "parser = vgtk.HierarchyArgmentParser()\n",
    "\n",
    "######### Experiment arguments\n",
    "exp_args = parser.add_parser(\"experiment\")\n",
    "exp_args.add_argument('--experiment-id', type=str, default='playground',\n",
    "                      help='experiment id (subpath after model_dir)')\n",
    "exp_args.add_argument('-d', '--dataset-path', type=str, required=True,\n",
    "                      help='path to datasets')\n",
    "exp_args.add_argument('--dataset', type=str, default='kpts',\n",
    "                      help='name of the datasets')    # used in 3d match\n",
    "exp_args.add_argument('--model-dir', type=str, default='trained_models/models',\n",
    "                      help='path to models (the root of all outputs)')\n",
    "exp_args.add_argument('-s', '--seed', type=int, default=2913,\n",
    "                      help='random seed')\n",
    "exp_args.add_argument('--run-mode', type=str, default='train',\n",
    "                      help='train | eval | test')\n",
    "\n",
    "######### Network arguments\n",
    "net_args = parser.add_parser(\"model\")\n",
    "net_args.add_argument('-m', '--model', type=str, default='inv_so3net_pn',\n",
    "                      help='type of model to use')\n",
    "net_args.add_argument('--input-num', type=int, default=1024,\n",
    "                      help='the number of the input points')\n",
    "net_args.add_argument('--output-num', type=int, default=32,\n",
    "                      help='the number of the input points')\n",
    "net_args.add_argument('--search-radius', type=float, default=0.4)\n",
    "net_args.add_argument('--normalize-input', action='store_true',\n",
    "                      help='normalize the input points')\n",
    "net_args.add_argument('--dropout-rate', type=float, default=0.,\n",
    "                      help='dropout rate, no dropout if set to 0')\n",
    "net_args.add_argument('--init-method', type=str, default=\"xavier\",\n",
    "                      help='method for weight initialization')\n",
    "net_args.add_argument('-k','--kpconv', action='store_true', help='If set, use a kpconv structure instead')\n",
    "net_args.add_argument('--kanchor', type=int, default=60, help='# of anchors used: {1,20,40,60}')\n",
    "net_args.add_argument('--normals', action='store_true', help='If set, add normals to the input (default setting is false)')\n",
    "net_args.add_argument('-u', '--flag', type=str, default='attention',\n",
    "                      help='pooling method: max | mean | attention | permutation')\n",
    "net_args.add_argument('--representation', type=str, default='quat',\n",
    "                      help='how to represent rotation: quaternion | ortho6d ')\n",
    "\n",
    "######### ESCNN arguments\n",
    "net_args.add_argument('--group', type=str, default='SO3',\n",
    "                      help='group symmetry in ClsSO3VoxConvModel: SO3 | I | S2')\n",
    "net_args.add_argument('--scale', type=int, default=1,\n",
    "                      help='factor for scaling up the channels in ClsSO3VoxConvModel')\n",
    "net_args.add_argument('--freq', type=int, default=2,\n",
    "                      help='max frequency in ClsSO3VoxConvModel')\n",
    "\n",
    "net_args.add_argument('--normal-for-sup', action='store_true', help='If set normal_for_sup, add normals to the input (default setting is false)')\n",
    "net_args.add_argument('--no-sym-kernel', action='store_true', help='If set, do not use efficient gathering (for comparison as a baseline)')\n",
    "\n",
    "net_args.add_argument('--v', action='store_true', help='If set, normal is used for supervision instead of transforming input')\n",
    "\n",
    "### modelnet40 classification specific options\n",
    "net_args.add_argument('--feat-all-anchors', action='store_true', help='If set feat_all_anchors, use features from all anchors to do retrieval')\n",
    "net_args.add_argument('--fc-on-concat', action='store_true', help='If set fc_on_concat, compress features from all anchors to do retrieval (cannot be true with feat_all_anchors)')\n",
    "\n",
    "### 3DMatch specific options\n",
    "net_args.add_argument('--p-pool-first', action='store_true', help='If set, do spatial pooling before anchor pooling in InvOutBlockMVD (3DMatch)')\n",
    "net_args.add_argument('--p-pool-to-cout', action='store_true', help='If set, map to cout in pointnet spatial pooling in InvOutBlockMVD (3DMatch)')\n",
    "# net_args.add_argument('--permute', action='store_true', help='If set, do permutation in InvOutBlockMVD (3DMatch)')\n",
    "net_args.add_argument('--permute-nl', action='store_true', help='If set, do permutation in InvOutBlockMVD (3DMatch)')\n",
    "net_args.add_argument('--permute-soft', action='store_true', help='If set, use soft permutation in InvOutBlockMVD (3DMatch)')\n",
    "\n",
    "\n",
    "######### Training arguments\n",
    "train_args = parser.add_parser(\"train\")\n",
    "train_args.add_argument('-e', '--num-epochs', type=int, default=None,\n",
    "                        help='maximum number of training epochs')\n",
    "train_args.add_argument('-i', '--num-iterations', type=int, default=1000000,\n",
    "                        help='maximum number of training iterations')\n",
    "train_args.add_argument('-b', '--batch-size', type=int, default=8,\n",
    "                        help='batch size to train')\n",
    "train_args.add_argument('--npt', type=int, default=24,\n",
    "                        help='number of point per fragment')\n",
    "train_args.add_argument('-t', '--num-thread', default=8, type=int,\n",
    "                        help='number of threads for loading data')\n",
    "train_args.add_argument('--no-augmentation', action=\"store_true\",\n",
    "                        help='no data augmentation if set true')\n",
    "train_args.add_argument('-r','--resume-path', type=str, default=None,\n",
    "                        help='Training using the pre-trained model')\n",
    "train_args.add_argument('--save-freq', type=int, default=20000,\n",
    "                        help='the frequency of saving the checkpoint (iters)')\n",
    "train_args.add_argument('-lf','--log-freq', type=int, default=100,\n",
    "                        help='the frequency of logging training info (iters)')\n",
    "train_args.add_argument('--eval-freq', type=int, default=5000,\n",
    "                        help='frequency of evaluation (iters)')\n",
    "train_args.add_argument('--debug-mode', type=str, default=None,\n",
    "                        help='if specified, train with a certain debug procedure')\n",
    "train_args.add_argument('--sigma', type=float, default=0.06,\n",
    "                     help='sigma from sdf to occ value')\n",
    "train_args.add_argument('--rot-ref-tgt', action=\"store_true\",\n",
    "                        help='regress rotation with tgt as reference if set true')\n",
    "train_args.add_argument('--topk', type=int, default=1,\n",
    "                        help='number of permutations to pick when regressing rotation')\n",
    "train_args.add_argument('--test_batch_size', type=int, default=8,\n",
    "                        help='batch size to train')\n",
    "\n",
    "\n",
    "######### Learning rate arguments\n",
    "lr_args = parser.add_parser(\"train_lr\")\n",
    "lr_args.add_argument('-lr', '--init-lr', type=float, default=1e-3,\n",
    "                     help='the initial learning rate')\n",
    "lr_args.add_argument('-lrt', '--lr-type', type=str, default='exp_decay',\n",
    "                     help='learning rate schedule type: exp_decay | constant')\n",
    "lr_args.add_argument('--decay-rate', type=float, default=0.5,\n",
    "                     help='the rate of exponential learning rate decaying')\n",
    "lr_args.add_argument('--decay-step', type=int, default=10000,\n",
    "                     help='the frequency of exponential learning rate decaying')\n",
    "\n",
    "\n",
    "######### Loss funtion arguments\n",
    "loss_args = parser.add_parser(\"train_loss\")\n",
    "loss_args.add_argument('--temperature', type=float, default=3,\n",
    "                       help='temperature in attention') # appears in modelnet models\n",
    "\n",
    "### modelnet40 classification specific options\n",
    "loss_args.add_argument('--attention-loss-type', type=str, default='no_reg',\n",
    "                       help='composition of attention loss function')\n",
    "loss_args.add_argument('--attention-margin', type=float, default=1.0,\n",
    "                       help='weight of rotational attention loss wrt category classification loss')\n",
    "loss_args.add_argument('--cls-attention-loss', action='store_true', \n",
    "                       help='if not set, only calculate category classification loss \\\n",
    "                             and leave rotational attention unsupervised, given model.flag==\"attention\"')\n",
    "loss_args.add_argument('--anchor-ab-loss', action='store_true', \n",
    "                       help='if set anchor_ab_loss, apply bce loss on 12*12 matrix instead of 60*12, given model.flag==\"permutation\"')\n",
    "loss_args.add_argument('--cross-ab', action='store_true', \n",
    "                       help='if set cross_ab, apply cross entropy loss on 12*12 matrix, on the input anchor dim, given model.flag==\"permutation\"')\n",
    "loss_args.add_argument('--cross-ab-T', action='store_true', \n",
    "                       help='if set cross_ab_T, apply cross entropy loss on 12*12 matrix, on the template anchor dim, given model.flag==\"permutation\"')\n",
    "\n",
    "### modelnet40 rotation registration specific options\n",
    "loss_args.add_argument('--reg-r-cls-loss', action='store_true', \n",
    "                       help='if set, also use cross entropy loss on rotation classification in registration task \\\n",
    "                             besides binary classification on anchors, given model.flag==\"permutation\"')\n",
    "\n",
    "### 3DMatch specific options\n",
    "loss_args.add_argument('--loss-type', type=str, default='soft',\n",
    "                       help='type of loss function')\n",
    "loss_args.add_argument('--margin', type=float, default=1.0,\n",
    "                       help='margin of hard batch loss')\n",
    "loss_args.add_argument('--equi-alpha', type=float, default=0.0,\n",
    "                       help='weight for equivariance loss')\n",
    "loss_args.add_argument('--equi-beta', type=float, default=0.0,\n",
    "                       help='weight for equivariance loss, given model.flag==\"permutation\"')\n",
    "loss_args.add_argument('--equi-gamma', type=float, default=0.0,\n",
    "                       help='weight for equivariance loss, given model.flag==\"attention\"')\n",
    "loss_args.add_argument('--use-innerp', action='store_true', \n",
    "                       help='if set, use inner product instead of cross entropy loss for equivariance training, given beta or gamma > 0')\n",
    "loss_args.add_argument('--equi-eta', type=float, default=0.0,\n",
    "                       help='weight for equivariance loss, given model.flag==\"attention\" and normals==True and normal_for_sup==True')\n",
    "\n",
    "### classification benchmark \n",
    "\n",
    "train_args.add_argument('--shift', action='store_true',\n",
    "                  help='scale and shift in training')\n",
    "train_args.add_argument('--jitter', action='store_true',\n",
    "                  help='jitter in training')\n",
    "train_args.add_argument('--dropout_pt', action='store_true',\n",
    "                  help='dropout input points in training')\n",
    "train_args.add_argument('--test_aug', action='store_true',\n",
    "                  help='use training augmentation in validation')\n",
    "train_args.add_argument('--train_rot', type=str, default='so3', const=None,\n",
    "                  help='rotation mode in training', choices=[None, 'z', 'so3', 'ico'],)   # by default so3, if --train_rot without following arg, then None \n",
    "train_args.add_argument('--test_rot', type=str, default=None,\n",
    "                  help='rotation mode in validation', choices=[None, 'z', 'so3', 'ico'],)\n",
    "train_args.add_argument('--group_test', action='store_true',\n",
    "                  help='test all conditions in validation, in which case test_aug and test_rot are ineffective')\n",
    "train_args.add_argument('--train_frac', type=float, default=1.0,\n",
    "                       help='use less than 1.0 to test if the network can be trained with fewer data. ')\n",
    "\n",
    "net_args.add_argument('--drop_xyz', action='store_true', help='If set, drop xyz in PointNet at the end of classification')\n",
    "\n",
    "# loss_args.add_argument('--attention-pretrain-step', type=int, default=3000,\n",
    "#                        help='step for scheduled pretrain (only used in attention model)')\n",
    "######### Eval arguments\n",
    "eval_args = parser.add_parser(\"eval\")\n",
    "\n",
    "######### Test arguments\n",
    "test_args = parser.add_parser(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c017a6-5b1a-4927-a571-4b11ab85d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
